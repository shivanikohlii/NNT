{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanikohli/Documents/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import data_utils\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import holidays\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('GEFcom2014Data/GEFCom2014-E.xlsx', skiprows =range(1,17545))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month'] = np.cos(2*np.pi*data.Date.dt.month / 12)\n",
    "data['dow'] = np.cos(2*np.pi*data.Date.dt.dayofweek / 7)\n",
    "data['hour'] = np.cos(2*np.pi*data.Date.dt.hour/24)\n",
    "us_holiday = holidays.US()\n",
    "data['is_holiday'] = 1 * data.Date.dt.date.apply(lambda x: x in us_holiday)\n",
    "data.drop(['Date', 'Hour'],1, inplace=True)\n",
    "c = list(data.columns)\n",
    "c = c[1:] + c[:1]\n",
    "data = data[c]\n",
    "c = list(data.columns)\n",
    "c = c[1:] + c[:1]\n",
    "data = data[c]\n",
    "data['CDD'] =  np.maximum(data.Temperature-65,0)\n",
    "data['HDD'] = np.maximum(65 - data.Temperature,0)\n",
    "scale = data.load.std()\n",
    "offset = data.load.mean()\n",
    "data.load = (data.load - offset) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:int(0.7*len(data))]\n",
    "val = data[int(0.7*len(data)):int(0.9*len(data))]\n",
    "test = data[int(0.9*len(data)):]\n",
    "nt = np.array(train)\n",
    "nv = np.array(val)\n",
    "ntest = np.array(test)\n",
    "x_train = nt[:,:-1]\n",
    "y_train = nt[:,-1]\n",
    "x_val = nv[:,:-1]\n",
    "y_val = nv[:,-1]\n",
    "x_test = ntest[:,:-1]\n",
    "y_test = ntest[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2seq_rnn(data, ys, history=24, future = 0):\n",
    "    xl = []\n",
    "    xff = []\n",
    "    yl = []\n",
    "    yf = []\n",
    "    for i in np.arange(history+1, len(data)-max(future,1)):\n",
    "        tmp1 = data[i-history:i+1]\n",
    "        tmp2 = ys[i-history-1:i].reshape(-1,1)\n",
    "        xl.append(np.append(tmp1, tmp2, axis=1))\n",
    "        xff.append(data[i+1:i+future+1])\n",
    "        yl.append(ys[i])\n",
    "        yf.append(ys[i:i+future])\n",
    "    return np.array(xl), np.array(xff), np.array(yl), np.array(yf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, xtf, yt, ytf = row2seq_rnn(x_train, y_train, history=24, future=24)\n",
    "#xv, xvf, yv, yvf = row2seq_rnn(x_val, y_val, history=24, future=24)\n",
    "xtt, xttf, ytt, yttf = row2seq_rnn(np.array(test)[:,:-1], np.array(test)[:,-1], history=24, future=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7840, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yttf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinball(y_true, y_pred, step =1):\n",
    "    ts = K.arange(step, 100, step, dtype=np.float32)/100\n",
    "    ts = K.reshape(ts,(1,-1))\n",
    "    y_true = K.reshape(y_true,(-1,1)) \n",
    "    pin = K.mean(K.maximum(y_true - y_pred, 0) * ts +\n",
    "                 K.maximum(y_pred - y_true, 0) * (1 - ts))\n",
    "    return pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 2\n",
    "hiddenU = 32\n",
    "val_dictionary = {}\n",
    "\n",
    "model = keras.models.Sequential(name = 'LSTM')\n",
    "model.add(keras.layers.LSTM(hiddenU, input_shape = xt.shape[1:], return_sequences = layer > 1))\n",
    "\n",
    "for i in range(layer-1):\n",
    "    model.add(keras.layers.LSTM(hiddenU, return_sequences = i < layer-2))\n",
    "model.add(Dense(99))\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-4)\n",
    "model.compile(loss=lambda y, yp: pinball(y, yp, 1), optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55172 samples, validate on 15729 samples\n",
      "Epoch 1/10\n",
      "55172/55172 [==============================] - 5s 85us/step - loss: 23.1803 - val_loss: 23.7216\n",
      "Epoch 2/10\n",
      "55172/55172 [==============================] - 4s 68us/step - loss: 21.3743 - val_loss: 21.4709\n",
      "Epoch 3/10\n",
      "55172/55172 [==============================] - 3s 63us/step - loss: 19.6275 - val_loss: 20.0285\n",
      "Epoch 4/10\n",
      "55172/55172 [==============================] - 4s 71us/step - loss: 18.2649 - val_loss: 18.7291\n",
      "Epoch 5/10\n",
      "55172/55172 [==============================] - 4s 64us/step - loss: 17.0024 - val_loss: 17.5040\n",
      "Epoch 6/10\n",
      "55172/55172 [==============================] - 4s 67us/step - loss: 15.8047 - val_loss: 16.3354\n",
      "Epoch 7/10\n",
      "55172/55172 [==============================] - 4s 69us/step - loss: 14.6615 - val_loss: 15.2138\n",
      "Epoch 8/10\n",
      "55172/55172 [==============================] - 4s 70us/step - loss: 13.5705 - val_loss: 14.1358\n",
      "Epoch 9/10\n",
      "55172/55172 [==============================] - 4s 72us/step - loss: 12.5319 - val_loss: 13.1061\n",
      "Epoch 10/10\n",
      "55172/55172 [==============================] - 4s 74us/step - loss: 11.5465 - val_loss: 12.1254\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(xt, yt, validation_data=(xv, yv), batch_size=768, epochs=100, verbose=True, callbacks=[keras.callbacks.ModelCheckpoint(\n",
    "'Weights/%s', save_best_only=True, save_weights_only=True)\n",
    "  , keras.callbacks.EarlyStopping(patience=20)])\n",
    "best_val = min(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n",
      "(7840, 99)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range(24):\n",
    "    preds = model.predict(xtt, batch_size= 768)\n",
    "    predictions.append(preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7840, 24, 99)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.array(predictions)\n",
    "prediction = prediction.reshape(7840,24,99)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gets_target_value(history =24, future = 24):\n",
    "    xtest2,xtf,yttf, ytest2 = row2seq_rnn(np.array(test)[:,:-1], np.array(test)[:,-1], history+future)\n",
    "    targets = []\n",
    "    for i in range(future):\n",
    "        targets.append(xtest2[:,history+1+i, -1].copy())\n",
    "    return np.array(targets).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_used = gets_target_value(history = 24,future = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_used = yttf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration for time 0\n",
      "iteration for time 1\n",
      "iteration for time 2\n",
      "iteration for time 3\n",
      "iteration for time 4\n",
      "iteration for time 5\n",
      "iteration for time 6\n",
      "iteration for time 7\n",
      "iteration for time 8\n",
      "iteration for time 9\n",
      "iteration for time 10\n",
      "iteration for time 11\n",
      "iteration for time 12\n",
      "iteration for time 13\n",
      "iteration for time 14\n",
      "iteration for time 15\n",
      "iteration for time 16\n",
      "iteration for time 17\n",
      "iteration for time 18\n",
      "iteration for time 19\n",
      "iteration for time 20\n",
      "iteration for time 21\n",
      "iteration for time 22\n",
      "iteration for time 23\n"
     ]
    }
   ],
   "source": [
    "count_list = []\n",
    "pin_list = []\n",
    "bins = [-1,1,10,20,30,40,50,60,70,80,90,99,101]\n",
    "for hour in range(24):\n",
    "    ts = (np.arange(1, 100, dtype=np.float32)/100).reshape(1,-1)\n",
    "    pin = np.mean(np.maximum(prediction[:,hour,:] - target_used[:,hour,None], 0) * ts + np.maximum(target_used[:,hour,None] - prediction[:,hour,:], 0) * (1 - ts), axis=(0))\n",
    "    pin_list.append(pin*scale)\n",
    "    counts, bins = np.histogram((prediction[:,hour,:]>target_used[:,hour,None]).sum(1), bins=bins)\n",
    "    count_list.append(counts)\n",
    "    print('iteration for time %d' %hour)\n",
    "count_array = np.array(count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qcs(expected, observed):\n",
    "    return ((observed-expected)**2/expected/len(expected)).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50373.512117346945\n",
      "50245.893707483\n",
      "50137.35403675359\n",
      "50103.471088435384\n",
      "49988.027754157236\n",
      "49861.18488992819\n",
      "49848.069881424795\n",
      "49743.29735922147\n",
      "49841.02591175359\n",
      "49838.150947184426\n",
      "49816.145431783836\n",
      "49788.52135298564\n",
      "49775.341151738474\n",
      "49944.43807870371\n",
      "49912.519864890404\n",
      "49910.97028533637\n",
      "49951.85465088813\n",
      "50019.286411092224\n",
      "50036.612988945584\n",
      "50054.021849017394\n",
      "50051.18622448979\n",
      "50089.462585034016\n",
      "50124.748133975816\n",
      "50301.67041052533\n"
     ]
    }
   ],
   "source": [
    "n_examples = count_array.sum(1)[0]\n",
    "half_of_the_bins = [0.01,0.09, 0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.09,0.01]\n",
    "prob_bins = np.array(half_of_the_bins)\n",
    "for i in range(24):\n",
    "    print(qcs(prob_bins*n_examples, count_array[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5125, 9.4875)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1833c3d2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,11))\n",
    "t = 0\n",
    "plt.bar(np.arange(12), count_array.sum(0)/count_array.sum(), width=0.975, align='center', color = '#003366' )\n",
    "# plt.xticks(range(10), [f'{i}% - {i+10}%' for i in range(0,110,10)])\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Normalized Frequency')\n",
    "plt.plot((-0.6, 0.6), (0.01, 0.01), color='r', lw=3)\n",
    "plt.plot((11-0.6, 11+0.6), (0.01, 0.01), color='r', lw=3)\n",
    "plt.plot((1-0.6, 1+0.6), (0.09, 0.09), color='r', lw=3)\n",
    "plt.plot((10-0.6, 10+0.6), (0.09, 0.09), color='r', lw=3)\n",
    "# plt.ylim(0,.045)\n",
    "for i in range(0,10):\n",
    "    plt.plot((i-0.6, i+0.6), (0.1, 0.1), color='#FFCC00', lw=3)\n",
    "# plt.plot((-100000, 100000), (0.1, 0.1), color='#FFCC00', lw=5)\n",
    "plt.xlim(-0.5 - 0.025/2,9.5- 0.025/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-94654965a80a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "plt.plot(predictions[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
